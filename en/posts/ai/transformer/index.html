<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Transformer基础知识 | Kend&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Seq2Seq模型 定义 包括两个部分： 编码器：将一个变长、可变类型的输入序列编码成一个固定长度、定长的向量，该向量中包含了输入序列的所有信息 解">
<meta name="author" content="Kend">
<link rel="canonical" href="https://iendi.github.io/en/posts/ai/transformer/">


<link crossorigin="anonymous" href="/assets/css/stylesheet.2b3a9b630d724ad2b56cb3217ca569e88f4344d61fa91c496bfd01d1128c4950.css" integrity="" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
        onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://iendi.github.io/img/1.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://iendi.github.io/img/1.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://iendi.github.io/img/1.png">
<link rel="apple-touch-icon" href="https://iendi.github.io/1.png">
<link rel="mask-icon" href="https://iendi.github.io/1.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://iendi.github.io/en/posts/ai/transformer/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script>
    MathJax = {
      tex: {
        inlineMath: [["$", "$"]],
      },
      displayMath: [
        ["$$", "$$"]
      ],
      svg: {
        fontCache: "global",
      },
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
    id="MathJax-script"
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
  ></script>


  

<meta property="og:title" content="Transformer基础知识" />
<meta property="og:description" content="Seq2Seq模型 定义 包括两个部分： 编码器：将一个变长、可变类型的输入序列编码成一个固定长度、定长的向量，该向量中包含了输入序列的所有信息 解" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://iendi.github.io/en/posts/ai/transformer/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-08T22:20:58+08:00" />
<meta property="article:modified_time" content="2023-06-08T22:20:58+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Transformer基础知识"/>
<meta name="twitter:description" content="Seq2Seq模型 定义 包括两个部分： 编码器：将一个变长、可变类型的输入序列编码成一个固定长度、定长的向量，该向量中包含了输入序列的所有信息 解"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "📚文章",
      "item": "https://iendi.github.io/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "💻AI",
      "item": "https://iendi.github.io/en/posts/ai/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Transformer基础知识",
      "item": "https://iendi.github.io/en/posts/ai/transformer/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Transformer基础知识",
  "name": "Transformer基础知识",
  "description": "Seq2Seq模型 定义 包括两个部分： 编码器：将一个变长、可变类型的输入序列编码成一个固定长度、定长的向量，该向量中包含了输入序列的所有信息 解",
  "keywords": [
    
  ],
  "articleBody": "Seq2Seq模型 定义 包括两个部分：\n编码器：将一个变长、可变类型的输入序列编码成一个固定长度、定长的向量，该向量中包含了输入序列的所有信息 解码器：每次输出一个字符，并把该字符作为下一次的输入，以此往复直到输出序列的结束标志为止 起始/终止符 以机器翻译为例，英翻中：\ntarget input：加[CLS]表示句子的开始 target output：加[SEP]表示结束 在==训练==时，用正确的target input（即ground truth）做输入，然后求loss进行参数更新，称为Teacher Forcing\n在==推理==时，[CLS]做输入，每次输出一个字符，并把该字符作为下一次的输入，直至预测到[SEP]\n如下图所示，输入的信息累积到$h_m$中，作为隐藏状态传给Decoder\nAttention 传统的Seq2Seq模型的Decoder部分，在生成下一状态时，只用到当前状态。而使用==attention==之后，Decoder每生成一个状态，都会重新计算和Encoder之间的相关性。\n计算$a_i$的公式如下。其中，$W_K$和$W_Q$是训练中得到的，$A$为参数矩阵，$k_i$、$q_i$均为列向量 $$ \\begin{array}l fk_i=fW_K \\cdot fh_i, \\text { for } i=1 \\text { to } m \\\\ fq_0=fW_Q \\cdot fs_0\\\\ fK=\\left \\{ k_1,k_2,…,k_m \\right \\} \\\\ \\tilde{\\alpha}_i=fK^T fq_0 \\\\ \\left[\\alpha_1, \\cdots, \\alpha_m\\right]=\\operatorname{Softmax}\\left(\\left[\\tilde{\\alpha}_1, \\cdots, \\tilde{\\alpha}_m\\right]\\right) \\end{array} $$\n计算得到$a_i$之后，计算$s_0$对应的$c_0$，并计算下一个状态$s_1$\n==注==：这里相比于RNN，attention在计算中多考虑了$c_0$ $$ fv_i=fW_V\\cdot fh_i\\\\ fc_0=\\alpha_1 fv_1+\\cdots+\\alpha_m fv_m\\\\ fs_1=\\tanh \\left(fA^{\\prime} \\cdot\\left[\\begin{array}l fx_1^{\\prime} \\\\ fs_0 \\\\ fc_0 \\end{array}\\right]+fb\\right) $$ 得到$s_1$之后，重新计算$a_i$，$k_i$不变，其他重新计算，得到$s_2$，以此类推\nSelf-Attention 隐藏变量$h_i$的计算公式如下 $$ fh_i=\\tanh \\left(fA \\cdot\\left[\\begin{array}l fx_i \\\\ fc_{i-1} \\end{array}\\right]+fb\\right) $$ 要得到$c_i$，首先要计算attention系数$a_i$，通过下列公式得到，其中align表示相关性公式 $$ a_i=align \\{h_i, (h_0,h_1,…h_i) \\} $$ 接着，计算得到$c_i$，并更新隐藏变量$h_i$ $$ fc_l=\\left\\{\\begin{matrix} h_1,\\qquad l=1 \\\\\\\n\\sum_{i=1}^l{a_i}{h_i} , l\u003e1 \\end{matrix}\\right. $$\nTransformer模型 Attention 和Seq2Seq模型类似，我们首先定义一个attention层，$k_:1$中的冒号表示其是一个列向量\n输入序列有两个，分别是Encoder Input和Decoder Input。接着，通过公式计算$a_:1$ $$ \\boldsymbol{\\alpha}_{: 1}=\\operatorname{Softmax}\\left(fK^T fq_{: 1}\\right) \\in bR^m $$ 最后，计算得到$c_:1$。其中，$a_{11}$表示列向量$a_:1$的第一个元素 $$ fc_{: 1}=\\alpha_{11} fv_{: 1}+\\cdots+\\alpha_{m 1} fv_{: m}=fV \\boldsymbol{\\alpha}_{: 1} $$\n综上，attention层的参数如下\n输入：包括Encoder Input和Decoder Input，$fC=Attn（fX,f{X’}）$ 输出：$fC=\\left[fc_{:1}, fc_{:2}, \\cdots, fc_{:t}\\right]$ Self-Attention 与Attention层类似，不同的是只有一个输入\n输入：$fC=Attn（fX,fX）$，可以看作两个输入都是X的Attention 输出：$fC=\\left[fc_{:1}, fc_{:2}, \\cdots, fc_{:t}\\right]$ Multi-Head 使用多头注意力，模型可以学习到不同的注意力权重，从而从不同的角度和视角来关注输入序列的信息\n以Multi-Head Self-Attention为例\nMulti-Head Self-Attention由L个Single-Head Self-Attention组成，即有L个$W_K、W_Q、W_V$矩阵\n最终得到L个$c_{:i}$，将其concat在一起\n搭建Encoder 单个Block由一个多头Self-Attention和全连接层组成，由于输入和输出的维度一样，可以采用残差结构\n搭建Decoder 单个的Decoder Block如下图所示\n==注==：对输入的$X’$，一般做的是Multi-Head Masked Self-Attention。即预测第i个单词不能获得i+1个单词的信息。因此Decoder部分被称为单向Transformer\n最后，将Encoder和Decoder组合起来，得到下图的结构\n参考资料：\nRNN模型与NLP应用\n",
  "wordCount" : "1546",
  "inLanguage": "en",
  "datePublished": "2023-06-08T22:20:58+08:00",
  "dateModified": "2023-06-08T22:20:58+08:00",
  "author":{
    "@type": "Person",
    "name": "Kend"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://iendi.github.io/en/posts/ai/transformer/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kend's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://iendi.github.io/img/1.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://iendi.github.io/en/" accesskey="h" title="Kend&#39;s Blog (Alt + H)">
                <img src="https://iendi.github.io/img/1.png" alt="" aria-label="logo"
                    height="35">Kend&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://iendi.github.io/en/search" title="🔍搜索 (Alt &#43; /)" accesskey=/>
                    <span>🔍搜索</span>
                </a>
            </li>
            <li>
                <a href="https://iendi.github.io/en/" title="🏠主页">
                    <span>🏠主页</span>
                </a>
            </li>
            <li>
                <a href="https://iendi.github.io/en/posts" title="📚文章">
                    <span>📚文章</span>
                </a>
            </li>
            <li>
                <a href="https://iendi.github.io/en/archives/" title="⏱时间轴">
                    <span>⏱时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://iendi.github.io/en/tags" title="🔖标签">
                    <span>🔖标签</span>
                </a>
            </li>
            <li>
                <a href="https://iendi.github.io/en/about" title="🙋🏻‍♂️关于">
                    <span>🙋🏻‍♂️关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://iendi.github.io/en/">主页</a>&nbsp;»&nbsp;<a href="https://iendi.github.io/en/posts/">📚文章</a>&nbsp;»&nbsp;<a href="https://iendi.github.io/en/posts/ai/">💻AI</a></div>
    <h1 class="post-title entry-hint-parent">
      Transformer基础知识
    </h1>
    <div class="post-meta"><span title='2023-06-08 22:20:58 +0800 CST'>2023-06-08</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Kend




&nbsp;|&nbsp;标签: &nbsp;
    </div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">文章目录</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#seq2seq%e6%a8%a1%e5%9e%8b" aria-label="Seq2Seq模型">Seq2Seq模型</a><ul>
                            
                    <li>
                        <a href="#%e5%ae%9a%e4%b9%89" aria-label="定义">定义</a></li>
                    <li>
                        <a href="#%e8%b5%b7%e5%a7%8b%e7%bb%88%e6%ad%a2%e7%ac%a6" aria-label="起始/终止符">起始/终止符</a></li>
                    <li>
                        <a href="#attention" aria-label="Attention">Attention</a></li>
                    <li>
                        <a href="#self-attention" aria-label="Self-Attention">Self-Attention</a></li></ul>
                    </li>
                    <li>
                        <a href="#transformer%e6%a8%a1%e5%9e%8b" aria-label="Transformer模型">Transformer模型</a><ul>
                            
                    <li>
                        <a href="#attention-1" aria-label="Attention">Attention</a></li>
                    <li>
                        <a href="#self-attention-1" aria-label="Self-Attention">Self-Attention</a></li>
                    <li>
                        <a href="#multi-head" aria-label="Multi-Head">Multi-Head</a></li>
                    <li>
                        <a href="#%e6%90%ad%e5%bb%baencoder" aria-label="搭建Encoder">搭建Encoder</a></li>
                    <li>
                        <a href="#%e6%90%ad%e5%bb%badecoder" aria-label="搭建Decoder">搭建Decoder</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>
  <div class="post-content"><h3 id="seq2seq模型">Seq2Seq模型<a hidden class="anchor" aria-hidden="true" href="#seq2seq模型">#</a></h3>
<h4 id="定义">定义<a hidden class="anchor" aria-hidden="true" href="#定义">#</a></h4>
<p>包括两个部分：</p>
<ul>
<li>编码器：将一个变长、可变类型的输入序列编码成一个固定长度、定长的向量，该向量中包含了输入序列的所有信息</li>
<li>解码器：每次输出一个字符，并把该字符作为下一次的输入，以此往复直到输出序列的结束标志为止</li>
</ul>
<h4 id="起始终止符">起始/终止符<a hidden class="anchor" aria-hidden="true" href="#起始终止符">#</a></h4>
<p>以机器翻译为例，英翻中：</p>
<ul>
<li>target input：加<code>[CLS]</code>表示句子的开始</li>
<li>target output：加<code>[SEP]</code>表示结束</li>
</ul>
<p>在==训练==时，用正确的target input（即<code>ground truth</code>）做输入，然后求loss进行参数更新，称为<strong>Teacher Forcing</strong></p>
<p>在==推理==时，<code>[CLS]</code>做输入，每次输出一个字符，并把该字符作为下一次的输入，直至预测到<code>[SEP]</code></p>
<p><img loading="lazy" src="v2-3312eb4931d64998df907768c14ddb1b_1440w.webp" alt="img"  />
</p>
<p>如下图所示，输入的信息累积到$h_m$中，作为隐藏状态传给Decoder</p>
<img src="image-20230608161836481.png" alt="image-20230608161836481" style="zoom:30%;" />
<h4 id="attention">Attention<a hidden class="anchor" aria-hidden="true" href="#attention">#</a></h4>
<p>传统的Seq2Seq模型的Decoder部分，在生成下一状态时，只用到当前状态。而使用==attention==之后，Decoder每生成一个状态，都会重新计算和Encoder之间的相关性。</p>
<img src="image-20230702173327598.png" alt="image-20230702173327598" style="zoom:80%;" />
<p>计算$a_i$的公式如下。其中，$W_K$和$W_Q$是训练中得到的，$A$为参数矩阵，$k_i$、$q_i$均为列向量
$$
\begin{array}l
fk_i=fW_K \cdot fh_i, \text { for } i=1 \text { to } m \\
fq_0=fW_Q \cdot fs_0\\
fK=\left \{ k_1,k_2,&hellip;,k_m \right \}  \\
\tilde{\alpha}_i=fK^T fq_0  \\
\left[\alpha_1, \cdots, \alpha_m\right]=\operatorname{Softmax}\left(\left[\tilde{\alpha}_1, \cdots, \tilde{\alpha}_m\right]\right)
\end{array}
$$</p>
<p>计算得到$a_i$之后，计算$s_0$对应的$c_0$，并计算下一个状态$s_1$</p>
<p>==注==：这里相比于RNN，attention在计算中多考虑了$c_0$
$$
fv_i=fW_V\cdot fh_i\\
fc_0=\alpha_1 fv_1+\cdots+\alpha_m fv_m\\
fs_1=\tanh \left(fA^{\prime} \cdot\left[\begin{array}l
fx_1^{\prime} \\
fs_0 \\
fc_0
\end{array}\right]+fb\right)
$$
得到$s_1$之后，重新计算$a_i$，$k_i$不变，其他重新计算，得到$s_2$，以此类推</p>
<h4 id="self-attention">Self-Attention<a hidden class="anchor" aria-hidden="true" href="#self-attention">#</a></h4>
<img src="image-20230702145951543.png" alt="image-20230702145951543" style="zoom: 47%;" />
<p>隐藏变量$h_i$的计算公式如下
$$
fh_i=\tanh \left(fA \cdot\left[\begin{array}l
fx_i \\
fc_{i-1}
\end{array}\right]+fb\right)
$$
要得到$c_i$，首先要计算attention系数$a_i$，通过下列公式得到，其中align表示相关性公式
$$
a_i=align \{h_i,    (h_0,h_1,&hellip;h_i) \}
$$
接着，计算得到$c_i$，并更新隐藏变量$h_i$
$$
fc_l=\left\{\begin{matrix}
h_1,\qquad l=1 \\\<br>
\sum_{i=1}^l{a_i}{h_i} , l&gt;1
\end{matrix}\right.
$$</p>
<h3 id="transformer模型">Transformer模型<a hidden class="anchor" aria-hidden="true" href="#transformer模型">#</a></h3>
<h4 id="attention-1">Attention<a hidden class="anchor" aria-hidden="true" href="#attention-1">#</a></h4>
<p>和Seq2Seq模型类似，我们首先定义一个attention层，$k_:1$中的冒号表示其是一个列向量</p>
<img src="image-20230702164358786.png" alt="image-20230702164358786" style="zoom:80%;" />
<p>输入序列有两个，分别是<code>Encoder Input</code>和<code>Decoder Input</code>。接着，通过公式计算$a_:1$
$$
\boldsymbol{\alpha}_{: 1}=\operatorname{Softmax}\left(fK^T fq_{: 1}\right) \in bR^m
$$
<img src="image-20230702164857108.png" alt="image-20230702164857108" style="zoom:80%;" /></p>
<p>最后，计算得到$c_:1$。其中，$a_{11}$表示列向量$a_:1$的第一个元素
$$
fc_{: 1}=\alpha_{11} fv_{: 1}+\cdots+\alpha_{m 1} fv_{: m}=fV \boldsymbol{\alpha}_{: 1}
$$</p>
<img src="image-20230702164956677.png" alt="image-20230702164956677" style="zoom:80%;" />
<p>综上，attention层的参数如下</p>
<ul>
<li>输入：包括<code>Encoder Input</code>和<code>Decoder Input</code>，$fC=Attn（fX,f{X&rsquo;}）$</li>
<li>输出：$fC=\left[fc_{:1}, fc_{:2}, \cdots, fc_{:t}\right]$</li>
</ul>
<h4 id="self-attention-1">Self-Attention<a hidden class="anchor" aria-hidden="true" href="#self-attention-1">#</a></h4>
<p>与Attention层类似，不同的是只有一个输入</p>
<ul>
<li>输入：$fC=Attn（fX,fX）$，可以看作两个输入都是X的Attention</li>
<li>输出：$fC=\left[fc_{:1}, fc_{:2}, \cdots, fc_{:t}\right]$</li>
</ul>
<img src="image-20230702172621261.png" alt="image-20230702172621261" style="zoom:80%;" />
<h4 id="multi-head">Multi-Head<a hidden class="anchor" aria-hidden="true" href="#multi-head">#</a></h4>
<p>使用多头注意力，模型可以学习到<strong>不同的</strong>注意力权重，从而从不同的角度和视角来关注输入序列的信息</p>
<p>以Multi-Head <strong>Self-Attention</strong>为例</p>
<p>Multi-Head Self-Attention由<code>L</code>个Single-Head Self-Attention组成，即有<code>L</code>个$W_K、W_Q、W_V$矩阵</p>
<p>最终得到L个$c_{:i}$，将其concat在一起</p>
<img src="image-20230703104527530.png" style="zoom:80%;" />
<h4 id="搭建encoder">搭建Encoder<a hidden class="anchor" aria-hidden="true" href="#搭建encoder">#</a></h4>
<p>单个Block由一个多头Self-Attention和全连接层组成，由于输入和输出的维度一样，可以采用残差结构</p>
<img src="image-20230703113534765.png" alt="image-20230703113534765" style="zoom:80%;" />
<h4 id="搭建decoder">搭建Decoder<a hidden class="anchor" aria-hidden="true" href="#搭建decoder">#</a></h4>
<p>单个的Decoder Block如下图所示</p>
<p>==注==：对输入的$X&rsquo;$，一般做的是Multi-Head <strong>Masked</strong> Self-Attention。即预测第i个单词不能获得i+1个单词的信息。因此Decoder部分被称为<strong>单向</strong>Transformer</p>
<img src="image-20230703172319983.png" alt="image-20230703172319983" style="zoom:80%;" />
<p>最后，将Encoder和Decoder组合起来，得到下图的结构</p>
<img src="image-20230703172444755.png" alt="image-20230703172444755" style="zoom:80%;" />
<blockquote>
<p>参考资料：</p>
<p><a href="https://www.bilibili.com/video/BV1YA411G7Ep/?spm_id_from=333.788&vd_source=a9906a59047f96daed0a464dfa0c358e">RNN模型与NLP应用</a></p>
</blockquote>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://iendi.github.io/en/posts/ai/bert/">
    <span class="title">« 上一页</span>
    <br>
    <span>Bert</span>
  </a>
  <a class="next" href="https://iendi.github.io/en/posts/ai/pyside6/">
    <span class="title">下一页 »</span>
    <br>
    <span>Pyside6</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>
        Copyright
        &copy;
        -2024
        <a href="https://iendi.github.io/en/" style="color:#939393;">Kend&#39;s Blog</a>
        All Rights Reserved
    </span>
    <a href="https://beian.miit.gov.cn/" target="_blank" style="color:#939393;"></a>&nbsp;
    <span>
        <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null"
           style="display:inline-block;text-decoration:none;height:20px;color:#939393;">
            <img src="" style="float:left;margin: 0px 5px 0px 0px;"/>
            
        </a>
    </span>
    <span id="busuanzi_container">
        <span class="fa fa-user"></span> <span id="busuanzi_value_site_uv"></span>
        <span class="fa fa-eye"></span> <span id="busuanzi_value_site_pv"></span>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"Kend's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"Kend's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = '📄复制';

        function copyingDone() {
            copybutton.innerText = '👌🏻已复制!';
            setTimeout(() => {
                copybutton.innerText = '📄复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\n————————————————\r\n' +
                    '版权声明：本文为「'+"Kend's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>
</body>

</html>
